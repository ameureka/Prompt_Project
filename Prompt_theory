主要介绍提示词工程涉及到一部分理论

https://github.com/JushBJJ/Mr.-Ranedeer-AI-Tutor

例如知名的 [CRISPE 框架](https://github.com/mattnigh/ChatGPT3-Free-Prompt-List)，CRISPE 分别代表以下含义：

- CR： Capacity and Role（能力与角色）。你希望 ChatGPT 扮演怎样的角色。
- I： Insight（洞察力），背景信息和上下文（坦率说来我觉得用 Context 更好）。
- S： Statement（指令），你希望 ChatGPT 做什么。
- P： Personality（个性），你希望 ChatGPT 以什么风格或方式回答你。
- E： Experiment（尝试），要求 ChatGPT 为你提供多个答案。

- **标识符**：`#`, `<>` 等符号(``, `[]`也是)，这两个符号依次标识`标题`,`变量`，控制内容层级，用于标识层次结构。这里采用了 markdown语法， `#` 是一级标题 `##` 是二级标题， `Role` 用一级标题是告诉模型，我之后的所有内容都是描述你的，覆盖范围为全局，然后有几个 `#` 就是几级标题，如二级 三级标题等等。
- **属性词**：`Role`, `Profile`, `Initialization` 等等，属性词包含语义，是对模块下内容的总结和提示，用于标识语义结构。

在生产级 AIGC 应用的开发中，**结构化 prompt 使得 prompt 的开发也像代码开发一样有规范。** 结构化 Prompt 的规范可以多种多样，用 json，yaml 实现都可以，

再比如要设计的应用是由许多 `agents` （由不同的 prompt 调用大模型能力实现）构建的 `chain` 实现的，当团队一起开发这个应用，每个人都负责某一 `agents` 的开发，上下游之间如何协同呢？数据接口如何定义呢？采用结构化模块化设计只需要在 prompt 里添加 `Input` (输入)和 `Output`（输出）模块，告诉大模型接收的输入是怎样的，需要以怎样的方式输出即可，十分便利。固定输入输出后，各开发人员完成自己的 agent 开发工作即可。

Role (角色) -> Profile（角色简介）—> Profile 下的 skill (角色技能) -> Rules (角色要遵守的规则) -> Workflow (满足上述条件的角色的工作流程) -> Initialization (进行正式开始工作的初始化准备) -> 开始实际使用

构建 Prompt 时，不妨参考优质模板的全局思维链路，熟练掌握后，完全可以对其进行增删改留调整得到一个适合自己使用的模板。例如当你需要控制输出格式，尤其是需要格式化输出时，完全可以增加 `Ouput` 或者 `OutputFormat` 这样的模块

从 prompting 的角度有哪些方法可以提高大模型在复杂任务上的性能表现呢？

汇总现有的一些方法：

1. 细节法：给出更清晰的指令，包含更多具体的细节
2. 分解法：将复杂的任务分解为更简单的子任务 （Let's think step by step, CoT，LangChain等思想）
3. 记忆法：构建指令使模型时刻记住任务，确保不偏离任务解决路径（system 级 prompt）
4. 解释法：让模型在回答之前进行解释，说明理由 （CoT 等方法）
5. 投票法：让模型给出多个结果，然后使用模型选择最佳结果 （ToT 等方法）
6. 示例法：提供一个或多个具体例子，提供输入输出示例 （one-shot, few-shot 等方法）

构建复杂高性能结构化 Prompt 有以下几种工作流：

1. 自动化生成初版结构化 Prompt -> 手工迭代调优 -> 符合需求的 prompt (推荐)
2. 自动化生成初版结构化 Prompt -> 自动化分析评估 Prompt -> 基于评估结果迭代调优 -> 符合需求的 prompt （推荐）
3. 手工套用现有模板 —> 手工迭代调优 -> 符合需求的 prompt

1, 2 较为推荐，能够大大降低工作量，大佬请随意。

自动化生成初版结构化 Prompt 推荐使用 [LangGPT](https://github.com/yzfly/LangGPT)，使用其他 Prompt 生成方法也可。

https://github.com/langgptai/LangGPT

https://langgptai.feishu.cn/wiki/WDfzwfTKwi1lyAkBcoCcu0sUnPc

如果返回到我们像DIFY 以及COZE 之中我们现在看下. 三者之间的提示词之间的区别是什么。

在大模型提示词编写的过程中，系统提示词（SYSTEM）、用户（USER）和助手（ASSISTANT）是三个核心组成部分，它们共同协作以引导模型生成符合预期的输出。以下是对它们在提示词编写过程中作用的详细说明：

**1. 系统提示词（SYSTEM）**

系统提示词是提示词编写的基础，它用于设定模型的角色、行为方式以及回答问题的上下文。具体来说：

- **定义角色**：系统提示词告诉模型它应该扮演什么角色，例如“您是一个旅行顾问”或“您是一个编程助手”。
- **提供指令**：它可以包含具体的指导，例如要求模型使用简洁的语言、避免偏见，或以特定格式（如列表或示例）回答。
- **设置上下文**：通过系统提示词，可以为模型提供背景信息或预期的工作范围。例如，“您的任务是帮助用户规划旅行，提供目的地建议和旅行贴士”。

例如，一个系统提示词可能是：

```
您是一个乐于助人的助手。您的目标是准确且礼貌地回答问题。如果用户的问题不明确，请请求澄清。
```

**2. 用户（USER）**

用户部分指的是用户输入的查询或请求，它是大模型生成响应的直接触发点。在提示词编写过程中：

- **多样性考虑**：编写者需要预判用户可能提出的问题类型。例如，在客户服务场景中，用户可能询问产品信息或故障排除。
- **明确性要求**：用户输入应尽量清晰，但提示词设计也需要考虑如何处理模糊或不完整的查询。
- **与系统提示词对齐**：用户输入的内容应与系统提示词设定的角色和任务范围相匹配，以确保模型能够有效响应。

例如，用户输入可能是：

```
我想去日本旅行，有什么需要知道的？
```

**3. 助手（ASSISTANT）**

助手部分是大模型根据系统提示词和用户输入生成的响应。在提示词编写中：

- **响应质量**：助手输出应符合系统提示词中定义的语气、风格和目标。例如，如果要求“礼貌且简洁”，则响应应体现这些特质。
- **灵活性与适应性**：助手需要根据用户输入的内容灵活调整，同时遵循系统提示词的约束。
- **示例引导**：在某些情况下，可以在系统提示词中加入示例（即“few-shot prompting”），以帮助模型理解预期的响应模式。例如：
    
    ```
    用户：法国的首都是哪里？
    助手：法国的首都是巴黎。
    ```
    

一个完整的助手响应可能是：

```
日本是一个充满文化和历史魅力的目的地。以下是一些关键信息：
- 语言：日语是官方语言，但旅游区常有人会说英语。
- 货币：使用日元（JPY），建议携带一些现金。
- 交通：公共交通系统发达，可考虑购买日本铁路通票。
您想了解更多具体方面的信息吗？
```

**提示词编写的整体过程**

在编写提示词时，这三个部分需要协同工作：

1. **明确目的**：首先确定模型的任务（如旅行建议、代码生成等），并通过系统提示词清晰传达。
2. **预判用户需求**：根据目标场景，设计系统提示词以应对可能的用户输入。
3. **优化响应**：通过调整系统提示词（如添加示例或具体指令），确保助手生成的响应符合预期。
4. **迭代改进**：根据模型的实际输出，逐步优化提示词，解决潜在问题（如语气不当或信息不准确）。
